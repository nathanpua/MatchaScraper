# MatchaScraper: A Cloud-Native Stock Monitoring System

### 1. Project Overview

**Project Name:** MatchaScraper - An Advanced, Cloud-Native Stock Monitoring System  
**Date:** 2025  

### 2. Executive Summary

This document outlines the architecture for a sophisticated, containerized scraping system engineered to monitor product availability on e-commerce websites. The entire infrastructure is provisioned and managed via Terraform, demonstrating a commitment to Infrastructure as Code (IaC) best practices. Designed for maximum cost-efficiency, the system operates on a schedule, running 12 hours daily on an Amazon EC2 instance. This instance is governed by an Auto Scaling Group and orchestrated by scheduled AWS Lambda functions, ensuring both high availability and minimal operational expense.

### 3. Business Requirements

#### 3.1 Primary Objectives
- **Targeted Scraping:** Precisely scrape product data from `Ippodo` and `Nakamura`.
- **High-Frequency Checks:** Refresh and validate product stock every minute.
- **Automated Scheduling:** Operate on a strict 12-hour daily schedule, starting at 10:00 AM.
- **Instantaneous Alerts:** Deliver real-time Telegram notifications upon product restocks.

#### 3.2 Key Success Metrics
- **Cost Efficiency:** Masterfully leverage the AWS Free Tier with a `t2.micro` instance and automated shutdowns to achieve near-zero cost.
- **High Availability:** Guarantee 100% uptime during the 12-hour operational window through a resilient Auto Scaling Group.
- **Data Accuracy:** Maintain 99.9% accuracy in stock detection.
- **Alert Latency:** Achieve a sub-60-second response time from stock detection to notification delivery.

### 4. Functional Requirements

#### 4.1 Core Features
The application's core logicâ€”scraping, stock detection, and notificationsâ€”is encapsulated within a Docker container. Its lifecycle is dynamically managed by a robust cloud infrastructure defined entirely in Terraform, ensuring consistency and reliability across all environments.

#### 4.2 Application Flow
```
10:00 AM: EventBridge triggers the "Scale-Up" Lambda function.
â”‚
â””â”€â”€ Lambda sets the Auto Scaling Group's desired capacity to 1.
    â”‚
    â””â”€â”€ The Auto Scaling Group launches a new EC2 instance.
        â”‚
        â””â”€â”€ The EC2 User Data script initiates the Docker container.
            â”‚
            â””â”€â”€ The Go application executes its continuous monitoring loop:
                â”œâ”€â”€ Scrape Ippodo & Nakamura in parallel.
                â”œâ”€â”€ Detect restocks and dispatch instant alerts.
                â””â”€â”€ Pause for 1 minute before repeating the cycle.
            
10:00 PM: EventBridge triggers the "Scale-Down" Lambda function.
â”‚
â””â”€â”€ Lambda sets the Auto Scaling Group's desired capacity to 0, gracefully terminating the instance.
```

### 5. Non-Functional Requirements

#### 5.1 Scalability
- While architected for a single EC2 instance to optimize cost, the system's foundation on an Auto Scaling Group allows for effortless scaling by adjusting the `desired_capacity` in the Terraform configuration.

#### 5.2 Reliability
- The use of an EC2 Auto Scaling Group provides exceptional resilience. If the instance fails for any reason, it is automatically terminated and replaced, guaranteeing high availability throughout the operational window.

### 6. Technical Architecture

#### 6.1 Project Structure
The project follows a clean, modular structure to promote separation of concerns and maintainability:

- **/app**: Houses the Go application source code (`main.go`, `scraper.go`, etc.).
- **/terraform**: Contains all Terraform Infrastructure as Code files (`main.tf`, `backend.tf`).
- **/lambda**: Includes the source code for the serverless scaling functions.
- **/.github/workflows**: Defines the automated CI/CD pipeline (`deploy.yml`).
- **/Dockerfile**: The blueprint for building the application's Docker image.

#### 6.2 Technology Stack

**Application & Logic:**
- **Language:** ğŸ¹ Go (Golang)
- **Web Scraping:** ğŸ•·ï¸ Colly
- **Notifications:** ğŸ’¬ Telegram Bot API

**Infrastructure & Automation:**
- **CI/CD:** ğŸš€ GitHub Actions
- **Infrastructure as Code:** ğŸ’œ Terraform
- **Compute:** ğŸ–¥ï¸ Amazon EC2 (`t2.micro`)
- **Containerization:** ğŸ³ Docker
- **Container Registry:** ğŸ“¦ Amazon ECR
- **Secrets Management:** ğŸ”’ AWS SSM Parameter Store
- **State Management:** ğŸ—„ï¸ Amazon S3 & DynamoDB
- **Logging & Monitoring:** ğŸ“Š Amazon CloudWatch
- **Scheduling:** ğŸ•’ Amazon EventBridge
- **Serverless Automation:** âš¡ AWS Lambda
- **Resilience:** ğŸ’ª EC2 Auto Scaling Group

#### 6.3 System Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AWS Cloud Infrastructure                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ ğŸ•’ EventBridge   â”‚ â”€â–º â”‚  âš¡ ScaleUp Lambda â”‚ â”€â–ºâ”‚ ğŸ’ª Auto   â”‚ â”‚
â”‚  â”‚    (10 AM Cron)  â”‚      â”‚   (Updates ASG)  â”‚     â”‚   Scaling â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   Group   â”‚ â”‚
â”‚                                                     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚       â”‚
â”‚  â”‚ ğŸ•’ EventBridge   â”‚ â”€â–º â”‚ âš¡ ScaleDown      â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚  â”‚    (10 PM Cron)  â”‚      â”‚    Lambda        â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       EC2 Instance Detail                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ ğŸ³ Docker Daemon       â”‚ â”€â–º â”‚ ğŸµ MatchaScraper Container  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                  â”‚                            â”‚
â”‚                                  â””â”€ Go Application (running)  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7. CI/CD Pipeline
The entire build, test, and deployment lifecycle is fully automated using GitHub Actions. A push to the `main` branch triggers a workflow that executes the following strategic steps:

1.  **Secure AWS Authentication**: Leverages OpenID Connect (OIDC) for a secure, passwordless authentication with AWS, eliminating the need for long-lived access keys.
2.  **Build & Test Docker Image**: Constructs a new Docker image from the source code and runs validation checks.
3.  **Push to Amazon ECR**: Tags the new image and pushes it to the private Amazon ECR repository.
4.  **Deploy Infrastructure with Terraform**: Atomically applies infrastructure changes using `terraform apply`, ensuring the production environment always reflects the `main` branch.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Push to `main`  â”œâ”€â–ºâ”‚ 1. Authenticate & Log In â”‚ â”€â–º â”‚ 2. Build Image   â”‚ â”€â–º â”‚ 3. Push to ECR     â”‚ â”€â–º â”‚ 4. Terraform Apply â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8. Cloud Infrastructure & Deployment

#### 8.1 Advanced Secrets Management
All secrets, including the `TELEGRAM_TOKEN` and `TELEGRAM_CHAT_ID`, are stored securely in **AWS SSM Parameter Store** as `SecureString` parameters. This follows security best practices by centralizing and encrypting sensitive data. The EC2 instance is granted a fine-grained IAM Role with permissions to access only these specific parameters at runtime, adhering to the principle of least privilege. This modern approach completely avoids hardcoding secrets or exposing them in CI/CD pipelines.

#### 8.2 Infrastructure as Code (Terraform)
The entire cloud environment is declaratively defined in Terraform, ensuring it is version-controlled, repeatable, and transparent.

**Remote State & Locking**
To enable seamless collaboration and reliable CI/CD runs, Terraform is configured with a remote backend. The state is persisted in an S3 bucket with versioning enabled, while a DynamoDB table provides robust state locking to prevent race conditions and ensure transactional integrity during deployments.

*backend.tf*
```terraform
terraform {
  backend "s3" {
    bucket         = "ippodo-scraper-tfstate-997092021600"
    key            = "global/s3/terraform.tfstate"
    region         = "ap-northeast-3"
    dynamodb_table = "ippodo-scraper-tf-lock"
    encrypt        = true
  }
}
```

**Dynamic Secret Injection**
At runtime, the EC2 instance's user data script dynamically fetches secrets from the SSM Parameter Store just before launching the container. This ensures the application always starts with the latest credentials without ever exposing them within the infrastructure code or instance metadata.

*Snippet from user data in `terraform/main.tf`*
```bash
#!/bin/bash
# ... docker setup ...

# Fetch secrets from SSM Parameter Store
TELEGRAM_TOKEN=$(aws ssm get-parameter --name "/ippodo-scraper/telegram-token" --with-decryption --query "Parameter.Value" --output text)
TELEGRAM_CHAT_ID=$(aws ssm get-parameter --name "/ippodo-scraper/telegram-chat-id" --with-decryption --query "Parameter.Value" --output text)

# ... login to ECR ...

# Run the Docker container with secrets injected as environment variables
docker run -d --restart always \
  -e TELEGRAM_TOKEN="$TELEGRAM_TOKEN" \
  -e TELEGRAM_CHAT_ID="$TELEGRAM_CHAT_ID" \
  ...
```

#### 8.3 Zero-Touch Deployment
The deployment process is fully automated. To roll out any change, developers simply push commits to the `main` branch, and the CI/CD pipeline handles the rest.

**Initial One-Time Setup:**
Before the first deployment, the following AWS resources must be created manually to bootstrap the Terraform backend and secrets:
1.  **S3 Bucket** for Terraform state storage.
2.  **DynamoDB Table** for Terraform state locking.
3.  **SSM Parameters** for the Telegram token and chat ID.

### 9. Cost-Effectiveness & AWS Free Tier Analysis

This project is meticulously designed to be extremely cost-effective, with an estimated monthly cost of **$0.00** for any user within their first 12 months of the AWS Free Tier.

Here is a detailed breakdown of the cost analysis:

| Service                       | Usage Details (12 hours/day)          | Free Tier Allowance (Monthly) | Estimated Cost |
| ----------------------------- | ------------------------------------- | ----------------------------- | :------------: |
| **Amazon EC2 (`t2.micro`)**   | 360 hours/month                       | 750 hours                     |     **$0.00**      |
| **Amazon ECR**                | < 500 MB storage                      | 500 MB                        |     **$0.00**      |
| **AWS Lambda**                | 60 requests/month                     | 1,000,000 requests            |     **$0.00**      |
| **Amazon EventBridge**        | 60 scheduled events/month             | 14,000,000 events             |     **$0.00**      |
| **SSM Parameter Store**       | < 100 API calls/month (Standard)      | 10,000 API calls              |     **$0.00**      |
| **Amazon S3**                 | < 1 GB storage (Terraform state)      | 5 GB                          |     **$0.00**      |
| **Amazon DynamoDB**           | Minimal RCU/WCU (Terraform lock)      | 25 RCU / 25 WCU               |     **$0.00**      |
| **Amazon CloudWatch**         | < 5 GB logs/month                     | 5 GB                          |     **$0.00**      |
| **Data Transfer**             | Minimal (notifications, image pull)   | 100 GB                        |     **$0.00**      |
| **Total Estimated Cost**      |                                       |                               |   **~$0.00**   |

*Note: This estimate assumes usage remains within the AWS Free Tier limits. Costs may vary based on actual usage and any changes to AWS pricing.*
